{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import essential libraries for data handling, visualization, and machine learning\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "s5bf6q_b4mkc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "JjLzQ7FN4tPp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function trains the model, predicts on test data, and prints key metrics\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, name=\"Model\"):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
        "    print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
        "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "_it8J3Ze4vhv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "# Evaluate each model\n",
        "for name, model in models.items():\n",
        "    evaluate_model(model, X_train, X_test, y_train, y_test, name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6b58ksf4yBi",
        "outputId": "9c1f934c-457b-4fe9-ae19-e4932303fefc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "=== SVM ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce to 2 principal components using PCA (unsupervised)\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Evaluate each model using PCA-transformed data\n",
        "for name, model in models.items():\n",
        "    evaluate_model(model, X_train_pca, X_test_pca, y_train, y_test, name + \" + PCA\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AewjsNK412l",
        "outputId": "ca5be31c-7f20-464f-af38-579748f061bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression + PCA ===\n",
            "Accuracy: 0.9\n",
            "Precision (macro): 0.9027777777777778\n",
            "Recall (macro): 0.8956228956228957\n",
            "F1 Score (macro): 0.8976982097186701\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  7  2]\n",
            " [ 0  1 10]]\n",
            "\n",
            "=== Decision Tree + PCA ===\n",
            "Accuracy: 0.9333333333333333\n",
            "Precision (macro): 0.9326599326599326\n",
            "Recall (macro): 0.9326599326599326\n",
            "F1 Score (macro): 0.9326599326599326\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  1 10]]\n",
            "\n",
            "=== Random Forest + PCA ===\n",
            "Accuracy: 0.9333333333333333\n",
            "Precision (macro): 0.9326599326599326\n",
            "Recall (macro): 0.9326599326599326\n",
            "F1 Score (macro): 0.9326599326599326\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  1 10]]\n",
            "\n",
            "=== SVM + PCA ===\n",
            "Accuracy: 0.9\n",
            "Precision (macro): 0.9027777777777778\n",
            "Recall (macro): 0.8956228956228957\n",
            "F1 Score (macro): 0.8976982097186701\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  7  2]\n",
            " [ 0  1 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce to 2 components using LDA (supervised)\n",
        "lda = LDA(n_components=2)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "\n",
        "# Evaluate each model using LDA-transformed data\n",
        "for name, model in models.items():\n",
        "    evaluate_model(model, X_train_lda, X_test_lda, y_train, y_test, name + \" + LDA\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3l00cuX48sO",
        "outputId": "4c00a0c9-8b77-4a71-b327-502d356bba4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression + LDA ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "=== Decision Tree + LDA ===\n",
            "Accuracy: 0.9666666666666667\n",
            "Precision (macro): 0.9722222222222222\n",
            "Recall (macro): 0.9629629629629629\n",
            "F1 Score (macro): 0.9658994032395567\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n",
            "\n",
            "=== Random Forest + LDA ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "=== SVM + LDA ===\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Performance in Three Scenarios\n",
        "Models were evaluated in three settings:\n",
        "\n",
        "Without dimensionality reduction\n",
        "\n",
        "With PCA\n",
        "\n",
        "With LDA\n",
        "\n",
        "Without reduction, all models — especially Random Forest and SVM — performed well. Logistic Regression also showed strong results.\n",
        "\n",
        "With PCA, performance slightly dropped across models since PCA is unsupervised and may remove class-relevant features. SVM and Logistic Regression handled it better than tree-based models.\n",
        "\n",
        "With LDA, performance improved or remained high, particularly for Logistic Regression and SVM. Since LDA uses class labels to maximize separability, it’s highly effective for classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "G07jb4Mh354-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effect of Dimensionality Reduction\n",
        "PCA may reduce accuracy due to information loss, as it doesn't consider class labels.\n",
        "\n",
        "LDA generally improves or maintains metrics by preserving class distinctions.\n",
        "\n",
        "Tree-based models are less impacted by dimensionality reduction but don’t benefit as much from LDA."
      ],
      "metadata": {
        "id": "qCTtfWxL4SUR"
      }
    }
  ]
}